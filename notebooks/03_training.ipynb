{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016f4461",
   "metadata": {},
   "source": [
    "# Train a CNN for anatomy-guided PET denoising and deblurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58124e8",
   "metadata": {},
   "source": [
    "import all modules we need in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e87acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pymirc.viewer as pv\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c8f36",
   "metadata": {},
   "source": [
    "Define a few helper functions to setup the model and load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(nfeat          = 30,      # number of featuers for Conv3D layers\n",
    "                 kernel_shape   = (3,3,3), # kernel shapes for Conv3D layers\n",
    "                 nhidden_layers = 6,       # number of hiddenlayers  \n",
    "                 batch_norm     = True,    # use batch normalization between Conv3D and activation\n",
    "                 add_final_relu = True):   # add a final ReLU activation at the end to clip negative values\n",
    "\n",
    "  \"\"\"Simple CNN that takes a batch of 3D volumes with 2 channel (e.g. PET and MR) and maps it to a batch\n",
    "     of 3D volumes with 1 channe (e.g. denoise PET)\n",
    "  \"\"\"  \n",
    "  # setup the input layer for batches of 3D tensors with two channels\n",
    "  inp = tf.keras.layers.Input(shape = (None, None, None, 2), name = 'input_layer')\n",
    "\n",
    "  # add a split layer such that we can add the first channel (PET) to the output\n",
    "  split = tf.keras.layers.Lambda( lambda x: tf.split(x, num_or_size_splits = 2, axis = -1), name = 'split')(inp)\n",
    "\n",
    "  # add all \"hidden\" layers\n",
    "  x   = inp\n",
    "  for i in range(nhidden_layers):\n",
    "    x = tf.keras.layers.Conv3D(nfeat, kernel_shape, padding = 'same',\n",
    "                               kernel_initializer = 'glorot_uniform', name = f'conv3d_{i+1}')(x)\n",
    "    if batch_norm:\n",
    "      x = tf.keras.layers.BatchNormalization(name = f'batchnorm_{i+1}')(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1,2,3], name = f'prelu_{i+1}')(x)\n",
    "\n",
    "\n",
    "  # add a (1,1,1) Conv layers with 1 feature to reduce along the feature dimension\n",
    "  x = tf.keras.layers.Conv3D(1, (1,1,1), padding='same', name = 'conv_final',\n",
    "                             kernel_initializer = 'glorot_uniform')(x)\n",
    "\n",
    "  # add first input channel\n",
    "  x = tf.keras.layers.Add(name = 'add')([x] + [split[0]])\n",
    "\n",
    "  # add a final ReLU to clip negative values\n",
    "  if add_final_relu:\n",
    "    x = tf.keras.layers.ReLU(name = 'final_relu')(x)\n",
    "\n",
    "  model  = tf.keras.Model(inputs = inp, outputs = x)\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_in_lps(fname):\n",
    "  \"\"\" function that loads nifti file and returns the volume and affine in \n",
    "      LPS orientation\n",
    "  \"\"\"\n",
    "  nii = nib.load(fname)\n",
    "  nii = nib.as_closest_canonical(nii)\n",
    "  vol = np.flip(nii.get_fdata(), (0,1))\n",
    "\n",
    "  return vol, nii.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_max(volume, n = 7):\n",
    "    \"\"\" function that return the max of a heavily smoothed version of the input volume\n",
    "        \n",
    "        for the smoothing we use tensorflows strided average pooling (which is fast) \n",
    "    \"\"\"\n",
    "    # to use tf's average pooling we first have to convert the numpy array to a tf tensor\n",
    "    # for the pooling layers, the shape of the input need to be [1,n0,n1,n2,1]\n",
    "    t = tf.convert_to_tensor(np.expand_dims(np.expand_dims(volume,0),-1).astype(np.float32))\n",
    "    \n",
    "    return tf.nn.avg_pool(t,2*n + 1,n,'SAME').numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(subject_path,    # subject path\n",
    "                  sim = 0,         # acquisition number (0,1,2) \n",
    "                  counts = 1e7):   # count level of PET (1e7 or 5e8)\n",
    "  \"\"\" function that loads and MR, PET and target nifti volumes from simulated brainweb volumes\n",
    "  \n",
    "      intensity scaling based on a robust max is also applied\n",
    "  \"\"\"\n",
    "  # get the subject number from the path\n",
    "  data_id = int(subject_path.parts[-1][-2:])\n",
    "\n",
    "  # setup the file names\n",
    "  mr_file   = pathlib.Path(subject_path) / 't1.nii.gz'\n",
    "  osem_file = pathlib.Path(subject_path) / f'sim_{sim}' / f'osem_psf_counts_{counts:0.1E}.nii.gz'\n",
    "  target_file = pathlib.Path(subject_path) / f'sim_{sim}' / 'true_pet.nii.gz'\n",
    "\n",
    "  # load nifti files in RAS orientation\n",
    "  mr, mr_aff = load_nii_in_lps(mr_file)\n",
    "  osem, osem_aff = load_nii_in_lps(osem_file)\n",
    "  target, target_aff = load_nii_in_lps(target_file)\n",
    "\n",
    "  # normalize the intensities of the MR and PET volumes\n",
    "  mr_scale   = robust_max(mr)\n",
    "  osem_scale = robust_max(osem)\n",
    "\n",
    "  mr     /= mr_scale\n",
    "  osem   /= osem_scale\n",
    "  target /= osem_scale\n",
    "\n",
    "  return osem, mr, target, osem_scale, mr_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34751479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augmentation(x, y, s0 = 64, s1 = 64, s2 = 64, contrast_aug = True):\n",
    "  \"\"\"data augmentation function for training \n",
    "     \n",
    "     the input x has shape (n0,n1,n2,2) and the input y has shape (n0,n1,n2,1)\n",
    "  \"\"\"\n",
    "\n",
    "  # do the same random crop of input and output\n",
    "  z = tf.concat([x,y], axis = -1)\n",
    "  z_crop = tf.image.random_crop(z, [s0,s1,s2,z.shape[-1]])\n",
    "\n",
    "  x_crop = z_crop[...,:2]\n",
    "  y_crop = z_crop[...,2]\n",
    "\n",
    "  # random contrast augmentation of the second input channel\n",
    "  if contrast_aug:\n",
    "    x_crop    = tf.unstack(x_crop, axis = -1)\n",
    "    x_crop[1] = tf.image.random_contrast(x_crop[1], 0.1, 1)\n",
    "    x_crop[1] = tf.image.random_brightness(x_crop[1], 0.5)\n",
    "    x_crop    = tf.stack(x_crop, axis = -1)\n",
    "\n",
    "  return x_crop, y_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5919045",
   "metadata": {},
   "source": [
    "Load all data into host memory and setup the training and validation data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9290141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust this variable to the path where the simulated PET/MR data from zenodo was unzipped\n",
    "data_dir    = pathlib.Path('brainweb_petmr')\n",
    "batch_size  = 10\n",
    "n_train_sub = 16\n",
    "patch_shape = (45,45,45)\n",
    "\n",
    "\n",
    "# get all the subjects paths\n",
    "subject_paths = sorted(list(data_dir.glob('subject??')))\n",
    "\n",
    "x = np.zeros((3*len(subject_paths),176,196,178,2), dtype = np.float32)\n",
    "y = np.zeros((3*len(subject_paths),176,196,178,1), dtype = np.float32)\n",
    "\n",
    "# load all the data sets and sort them into the x and y numpy arrays\n",
    "for i,subject_path in enumerate(subject_paths):\n",
    "  for sim in range(3):\n",
    "    print(f'loading {subject_path} simulation {sim}')\n",
    "    data = load_data_set(subject_path, sim = sim, counts = 1e7)   \n",
    "    x[3*i + sim,...,0] = data[0][40:-40,30:-30,40:-40]\n",
    "    x[3*i + sim,...,1] = data[1][40:-40,30:-30,40:-40]\n",
    "    y[3*i + sim,...,0] = data[2][40:-40,30:-30,40:-40]\n",
    "\n",
    "# split the data in training and validation data\n",
    "\n",
    "x_train = x[:(3*n_train_sub)]\n",
    "y_train = y[:(3*n_train_sub)]\n",
    "x_val   = x[(3*n_train_sub):]\n",
    "y_val   = y[(3*n_train_sub):]\n",
    "\n",
    "del x\n",
    "del y\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_loader.shuffle(x_train.shape[0]).map(lambda x,y: train_augmentation(x,y, s0 = patch_shape[0], s1 = patch_shape[1], s2 = patch_shape[2])).batch(batch_size).prefetch(4)\n",
    "\n",
    "\n",
    "val_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_loader.shuffle(x_val.shape[0]).map(lambda x,y: train_augmentation(x,y, s0 = patch_shape[0], s1 = patch_shape[1], s2 = patch_shape[2])).batch(x_val.shape[0]).prefetch(2)\n",
    "\n",
    "xv, yv = list(val_dataset.take(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830dfe2d",
   "metadata": {},
   "source": [
    "Setup the model and start training. For decent convergence **1000-2000 epochs** should be used, which takes a few hours on a modern GPU. To just check whether everything is working, we only use **10 epochs which is far to less.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982126be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs       = 10                                 # number of training epochs\n",
    "learning_rate = 1e-3                               # initial learning rate \n",
    "loss          = tf.keras.losses.MeanSquaredError() # loss function to use\n",
    "\n",
    "\n",
    "model = simple_model()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate), loss = loss)\n",
    "\n",
    "# setup a directory where we save the ouput\n",
    "logdir = pathlib.Path(f'model_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "logdir.mkdir(exist_ok = True)\n",
    "\n",
    "# setup a few useful callbacls\n",
    "# save model with best validation loss\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(logdir / 'trained_model', \n",
    "                                                monitor           = 'val_loss', \n",
    "                                                verbose           = 1, \n",
    "                                                save_best_only    = True, \n",
    "                                                save_weights_only = False, \n",
    "                                                mode              ='min')\n",
    "\n",
    "# save a csv log file with the training and validation loss after each epoch\n",
    "csvlog    = tf.keras.callbacks.CSVLogger(logdir / 'log.csv')\n",
    "\n",
    "# reduce learning rate by a factor of 2 if validation loss does not improve for 100 epochs\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, \n",
    "                                                 patience = 100, verbose = 1, min_lr = 1e-4)\n",
    "\n",
    "# tenor board callback to e.g. compute histograms of activations\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir = logdir / 'tensor_board', histogram_freq = 5, write_graph = False)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_dataset, epochs = nepochs, validation_data = (xv,yv),\n",
    "                    callbacks = [checkpoint, csvlog, lr_reduce, tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f86ee",
   "metadata": {},
   "source": [
    "plot the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b111cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(np.arange(1, nepochs + 1), history.history['loss'], label = 'loss')\n",
    "ax.semilogy(np.arange(1, nepochs + 1), history.history['val_loss'], label = 'validation loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "ax.grid(ls=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce349a07",
   "metadata": {},
   "source": [
    "Use the train model to make predictions based on all validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model (the model after the last epoch does not need to have the lowest validation loss)\n",
    "trained_model = tf.keras.models.load_model(logdir / 'trained_model')\n",
    "\n",
    "p = trained_model.predict(x_val, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0ec51",
   "metadata": {},
   "source": [
    "Show the predictions. You can click in the plots and use your arrow keys to move through the slices / batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable interactive plots with the ipympl package\n",
    "%matplotlib widget\n",
    "\n",
    "ims = 4*[{'vmin':0,'vmax':1.5}] + [{'vmin':-0.4,'vmax':0.4, 'cmap':plt.cm.bwr}]\n",
    "vi = pv.ThreeAxisViewer([x_val[...,0].squeeze(),x_val[...,1].squeeze(),p.squeeze(),y_val.squeeze(), \n",
    "                         p.squeeze() - y_val.squeeze()], \n",
    "                         imshow_kwargs = ims, \n",
    "                         rowlabels = ['input PET', 'input MR', 'prediction','target','absolute bias'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
