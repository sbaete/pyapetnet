{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ac8cb6",
   "metadata": {},
   "source": [
    "# Setting up and training simple convolutional networks with tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf29f6",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to set up simple 3D convolutional network with tensorflow and keras.\n",
    "As an example, we will set up a network that takes a batch of 3D tensors with 2 channels (e.g. PET and MR) as input and outputs a batch of 3D tensors with 1 channel (denoised and deblurred PET image).\n",
    "Moreover, we will see how to train a model and how to monitor training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464949a5",
   "metadata": {},
   "source": [
    "The model that we will setup in this tutorial will look like the figure below, except that we won't split and\n",
    "concatenate the features in the first layer.\n",
    "\n",
    "![foo bar](https://raw.githubusercontent.com/gschramm/pyapetnet/master/figures/fig_1_apetnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1894e63",
   "metadata": {},
   "source": [
    "## Setting up a simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules used in this tutorial\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51065a",
   "metadata": {},
   "source": [
    "Before setting up our first model, we define a short helper function that allows us to visualize models in a matplotlib figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ae664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "def show_model(model):\n",
    "  \"\"\" function that saves structure of a model into png and shows it with matplotlib\n",
    "  \"\"\"\n",
    "  tmp_file = NamedTemporaryFile(prefix = 'cnn_model_', suffix = '.png', dir = '.')\n",
    "  tf.keras.utils.plot_model(model, to_file= tmp_file.name, show_shapes = True, dpi = 192)\n",
    "  img = mpimg.imread(tmp_file)\n",
    "  fig, ax = plt.subplots(figsize = (12,12))\n",
    "  img = plt.imshow(img)\n",
    "  ax.set_axis_off()\n",
    "\n",
    "  return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fa63f",
   "metadata": {},
   "source": [
    "Let's setup the network described above. We can setup the whole network with layers that are predefined in keras which makes life easy. Since our desired output (denoised and beblurred PET image) is \"close\" to first input channel (the noisy and blurry PET image), we add the first input channel to the output. The batch and spatial dimensions of all layers are \"None\", since all layers preserve those dimensions. This in turn means the model an be applied to all batch sizes and spatial dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(nfeat          = 30,      # number of featuers for Conv3D layers\n",
    "                 kernel_shape   = (3,3,3), # kernel shapes for Conv3D layers\n",
    "                 nhidden_layers = 6,       # number of hiddenlayers  \n",
    "                 batch_norm     = True,    # use batch normalization between Conv3D and activation\n",
    "                 add_final_relu = True):   # add a final ReLU activation at the end to clip negative values\n",
    "\n",
    "  # setup the input layer for batches of 3D tensors with two channels\n",
    "  inp = tf.keras.layers.Input(shape = (None, None, None, 2), name = 'input_layer')\n",
    "\n",
    "  # add a split layer such that we can add the first channel (PET) to the output\n",
    "  split = tf.keras.layers.Lambda( lambda x: tf.split(x, num_or_size_splits = 2, axis = -1), name = 'split')(inp)\n",
    "\n",
    "  # add all \"hidden\" layers\n",
    "  x   = inp\n",
    "  for i in range(nhidden_layers):\n",
    "    x = tf.keras.layers.Conv3D(nfeat, kernel_shape, padding = 'same',\n",
    "                               kernel_initializer = 'glorot_uniform', name = f'conv3d_{i+1}')(x)\n",
    "    if batch_norm:\n",
    "      x = tf.keras.layers.BatchNormalization(name = f'batchnorm_{i+1}')(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1,2,3], name = f'prelu_{i+1}')(x)\n",
    "\n",
    "\n",
    "  # add a (1,1,1) Conv layers with 1 feature to reduce along the feature dimension\n",
    "  x = tf.keras.layers.Conv3D(1, (1,1,1), padding='same', name = 'conv_final',\n",
    "                             kernel_initializer = 'glorot_uniform')(x)\n",
    "\n",
    "  # add first input channel\n",
    "  x = tf.keras.layers.Add(name = 'add')([x] + [split[0]])\n",
    "\n",
    "  # add a final ReLU to clip negative values\n",
    "  if add_final_relu:\n",
    "    x = tf.keras.layers.ReLU(name = 'final_relu')(x)\n",
    "\n",
    "  model  = tf.keras.Model(inputs = inp, outputs = x)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b67c4",
   "metadata": {},
   "source": [
    "Let's print a summary of all layers, connections and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbf99c",
   "metadata": {},
   "source": [
    "Let's visualize the model using the helper function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = show_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba64cf",
   "metadata": {},
   "source": [
    "## Training a neural network with tensorflow and keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc087c",
   "metadata": {},
   "source": [
    "Training a keras model is done via ```model.fit()``` as described in https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "\n",
    "First, we need to configure the loss function and optimizer for training using ```model.compile()``` where we specify a loss function, an optimizer and a learning rate. See https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
    "\n",
    "In this tutorial, we use Mean Squared Error as the loss and the popular Adam optimizer with a learning rate of 1e-3. Note thati:\n",
    "- you can also you other loss functions such as Mean Absolute Error that measure the distance between the predicted and target image\n",
    "- 1e-3 is the default starting step size for the Adam optimizer that works well for many applications. In principle, we could also try a bigger learning rate, but that might lead to divergence. Using a smaller learning rate (e.g. 3e-4) is also possible, but will slow down training. A nice simplified explaination of different optimizers is shown here: https://www.youtube.com/watch?v=gmwxUy7NYpA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss          = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate), loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3541e88",
   "metadata": {},
   "source": [
    "After configuring the loss function, optimizer and learning right we can start training. In this tutorial we will use simulated blobs to demonstrate how the training works. Training on \"real\" is the same. We only have to replace the data loader as shown in the previous tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate artificial training and validation data\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "\n",
    "ndata      = 50            # number of simulated data sets\n",
    "ntrain     = 40            # number of data sets used for training (rest used for validation)\n",
    "batch_size = 10\n",
    "im_shape   = (29,29,29)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "x = np.zeros((ndata,) + im_shape + (2,), dtype = np.float32)\n",
    "y = np.zeros((ndata,) + im_shape + (1,), dtype = np.float32)\n",
    "\n",
    "for i in range(ndata):\n",
    "  # generate a few random binary blobs by thresholding filtered random images\n",
    "  blobs  = (gaussian_filter(np.random.rand(*im_shape),4.5/2.35) > 0.5).astype(np.float32)\n",
    "  # the target image is the blob image shifted by a random constand  \n",
    "  target = (np.random.rand() + 0.5)*blobs + 0.2*np.random.rand()\n",
    "   \n",
    "  y[i,:,:,:,0] = target\n",
    "  # the first input channel is a blurred version of the target image  \n",
    "  x[i,:,:,:,0] = gaussian_filter(target,3)\n",
    "  # the second image is the target with different contrast (structural prior image)  \n",
    "  x[i,:,:,:,1] = (np.random.rand()-0.5)*blobs + 0.2*np.random.rand()\n",
    "    \n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x[:ntrain,...], y[:ntrain,...]))\n",
    "train_dataset = train_loader.shuffle(len(x)).batch(batch_size).prefetch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09722000",
   "metadata": {},
   "source": [
    "Let's run a short demo training. We only use a few (50) epochs to results quickly. In real trainings usually around 500 - 1000 epochs are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 50\n",
    "history = model.fit(train_dataset, epochs = nepochs, validation_data = (x[ntrain:,...], y[ntrain:,...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d5d92",
   "metadata": {},
   "source": [
    "Let's plot the evolution of the training and validation loss to see how well the training worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22784b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(np.arange(1, nepochs + 1), history.history['loss'], label = 'loss')\n",
    "ax.semilogy(np.arange(1, nepochs + 1), history.history['val_loss'], label = 'validation loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "ax.grid(ls=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a30098",
   "metadata": {},
   "source": [
    "After training, we can use the trained model to make predictions from the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x[40:,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a9f8e",
   "metadata": {},
   "source": [
    "Let's show a few of the validation data sets and the corresponding predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15441de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymirc.viewer as pv\n",
    "# enable interactive plots with the ipympl package\n",
    "%matplotlib widget\n",
    "vi = pv.ThreeAxisViewer([x[ntrain:,...,0].squeeze(), x[ntrain:,...,1].squeeze(), y[ntrain:,...,0].squeeze(), pred[...,0].squeeze()],\n",
    "                             imshow_kwargs = [{'vmin':0,'vmax':1.6},{'vmin':-0.6,'vmax':0.6},{'vmin':0,'vmax':1.6},{'vmin':0,'vmax':1.6}], \n",
    "                             rowlabels = [f'input 0', f'input 1', f'target', f'prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f02f63",
   "metadata": {},
   "source": [
    "## Now it's your turn\n",
    "\n",
    "Now we know everthing that we need to set up and train a simple 3D convoltion neural network aimed to do structure guided deblurring and denoising.\n",
    "\n",
    "Now it's your turn to:\n",
    "1. Train a network on the simulated brainweb data using the tensorflow data input pipeline of the previous tutorial. Make sure that use small random patches (size ca 29,29,29) to avoid GPU out of memory errors. To get decent training results, we recommend to use 500-1000 epochs. Use the first 40 for training and the last twenty for validation to monitor potential over-fitting.\n",
    "2. (optional) Perform some stress tests of your network. What happens e.g. when the change (flip) the contrast of the MR images? What happens if we apply spatial flips to the images?\n",
    "3. (optional) Calculate the PSNR between the predictions and the target images.\n",
    "4. (optional) Have a look at keras callbacks that can be passed to ```model.fit()``` to e.g. save the model with the best validation loss, or to dynamically decrease the learning rate. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "5. (optional) Run trainings with different network hyper parameters (number of hidden layers, number of featuers, batch size ...) and compare the training and validation loss. Visualize a few predictions from the validation data as well. In total we have 3x20=60 simulated data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
