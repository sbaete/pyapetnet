{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charming-focus",
   "metadata": {},
   "source": [
    "# Training a convolutional network for anatomy guided PET image denoising and deblurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-polyester",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to set up and train a simple 3D convolutional network for anatomical-guided denoising and deblurring of PET images.\n",
    "\n",
    "We will set up a network that takes a batch of 3D tensors with 2 channels (e.g. PET and MR) as input and outputs a batch of 3D tensors with 1 channel (denoised and deblurred PET image).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-phoenix",
   "metadata": {},
   "source": [
    "The approach and the model architecture that we will use in this tutorial is inspired by Schramm et al., [\"Approximating anatomically-guided PET reconstruction in image space using a convolutional neural network\"](https://doi.org/10.1016/j.neuroimage.2020.117399), NeuroImage 2021, DOI 10.1016/j.neuroimage.2020.117399\n",
    "\n",
    "![foo bar](https://raw.githubusercontent.com/gschramm/pyapetnet/master/figures/fig_1_apetnet.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-london",
   "metadata": {},
   "source": [
    "This tutotial uses simulated PET/MR data based on the brain web. However, applying the same training strategy to real data should be straight forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-adelaide",
   "metadata": {},
   "source": [
    "To setup and train the model, we will use tensorflow and keras to show the basic concepts of setting up and training a model. Of course, the same concepts can be used with any other deep learning frame work (such as e.g. pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-evaluation",
   "metadata": {},
   "source": [
    "### The tutorial is split into two notebooks\n",
    "1. In the first notebook ([01_tf_data.ipynb](01_tf_data.ipynb)), we will learn how to setup a data loader pipeline to efficiently create mini batches of training data including data augmentation.\n",
    "2. In the second notebook ([02_tf_models.ipynb](02_tf_models.ipynb)), we will learn how to setup and train the model architecture shown above.\n",
    "\n",
    "Finally, it wil be you turn to combine the knowledge of these two notebooks to train your own network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-israel",
   "metadata": {},
   "source": [
    "### To run this tutorial, you need to install the following python packages\n",
    "- ```pyapetnet >= 1.1``` (or later, will install dependencies tensorflow, nibabel, pymirc, ...) \n",
    "- ```pydot >= 1.4``` \n",
    "- ```graphviz >= 0.16```\n",
    "- ```ipympl >= 0.7```\n",
    "\n",
    "All packages are available on pypi and can be installed via:\n",
    "```\n",
    "pip install pyapetnet\n",
    "pip install pydot\n",
    "pip install graphviz\n",
    "pip install ipympl\n",
    "```\n",
    "\n",
    "**If you are running these notebooks as part of the Training School for the Synergistic Image Reconstruction Framework (SIRF) and Core Imaging Library (CIL) on the <font color='red'>STFC jupyter cloud servers</font>, these packages are already available and do not need to be installed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-trauma",
   "metadata": {},
   "source": [
    "### Downloading data used in this tutorial\n",
    "\n",
    "The data sets that we will use in these notebooks are available on zenodo at:\n",
    "https://zenodo.org/record/4897350/files/brainweb_petmr.zip\n",
    "\n",
    "Please download this zip file (ca 10GB, download takes ca 15min depending on your connection) and unzip it and place it somewhere on your machine.\n",
    "In all notebooks, this location will be stored in the ```data_path``` variable which **might need to\n",
    "be adjusted.**\n",
    "\n",
    "**If you are running these notebooks as part of the Training School for the Synergistic Image Reconstruction Framework (SIRF) and Core Imaging Library (CIL) on the <font color='red'>STFC jupyter servers</font>, the data is available in\n",
    "```/mnt/materials/SIRF/Fully3D/DL/brainweb_petmr/``` and does not need to be downloaded.**\n",
    "\n",
    "The cell below looks for all subjects in ```data_path``` and find 20 subjects.\n",
    "If ```data_path``` is correctly set, the output should look sth like.\n",
    "\n",
    "```\n",
    "01 brainweb_petmr/subject04\n",
    "02 brainweb_petmr/subject05\n",
    "03 brainweb_petmr/subject06\n",
    "04 brainweb_petmr/subject18\n",
    "05 brainweb_petmr/subject20\n",
    "06 brainweb_petmr/subject38\n",
    "07 brainweb_petmr/subject41\n",
    "08 brainweb_petmr/subject42\n",
    "09 brainweb_petmr/subject43\n",
    "10 brainweb_petmr/subject44\n",
    "11 brainweb_petmr/subject45\n",
    "12 brainweb_petmr/subject46\n",
    "13 brainweb_petmr/subject47\n",
    "14 brainweb_petmr/subject48\n",
    "15 brainweb_petmr/subject49\n",
    "16 brainweb_petmr/subject50\n",
    "17 brainweb_petmr/subject51\n",
    "18 brainweb_petmr/subject52\n",
    "19 brainweb_petmr/subject53\n",
    "20 brainweb_petmr/subject54\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spanish-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 brainweb_petmr/subject04\n",
      "02 brainweb_petmr/subject05\n",
      "03 brainweb_petmr/subject06\n",
      "04 brainweb_petmr/subject18\n",
      "05 brainweb_petmr/subject20\n",
      "06 brainweb_petmr/subject38\n",
      "07 brainweb_petmr/subject41\n",
      "08 brainweb_petmr/subject42\n",
      "09 brainweb_petmr/subject43\n",
      "10 brainweb_petmr/subject44\n",
      "11 brainweb_petmr/subject45\n",
      "12 brainweb_petmr/subject46\n",
      "13 brainweb_petmr/subject47\n",
      "14 brainweb_petmr/subject48\n",
      "15 brainweb_petmr/subject49\n",
      "16 brainweb_petmr/subject50\n",
      "17 brainweb_petmr/subject51\n",
      "18 brainweb_petmr/subject52\n",
      "19 brainweb_petmr/subject53\n",
      "20 brainweb_petmr/subject54\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# adjust this variable to the path where the simulated PET/MR data from zenodo was unzipped\n",
    "data_path = pathlib.Path('brainweb_petmr')\n",
    "\n",
    "# print all downloaded subjects\n",
    "for i, p in enumerate(sorted(list(data_path.glob('subject??')))):\n",
    "  print(f'{(i+1):02}', str(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
